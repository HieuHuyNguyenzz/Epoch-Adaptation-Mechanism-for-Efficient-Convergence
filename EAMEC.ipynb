{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWqhwgqf-wem"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gc\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "\n",
        "from fedartml import SplitAsFederatedData\n",
        "import flwr as fl\n",
        "from logging import WARNING, INFO\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        "    Metrics\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "from flwr.server.strategy.aggregate import aggregate\n",
        "from flwr.server.strategy import Strategy\n",
        "import threading\n",
        "from abc import ABC, abstractmethod\n",
        "import random\n",
        "from flwr.server.criterion import Criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atd9Ef5wSiQ_",
        "outputId": "c3280a34-75d9-49a3-a3dc-d8f663502875"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "N = -104.0\n",
        "U = np.random.uniform(1.0, 5.0, size=50) * 10**4\n",
        "f = np.random.uniform(1.0, 2.0, size=50) * 10**9\n",
        "B = np.random.uniform(1.0, 10.0, size=50)\n",
        "p = np.random.uniform(20.0, 40.0, size=50)\n",
        "x, y = np.random.uniform(-5000.0, 5000.0, size=50), np.random.uniform(-5000.0, 5000.0, size=50)\n",
        "M = 185.82\n",
        "#cifar: 1410\n",
        "#emnist: 185.82\n",
        "#mnist: 173.54\n",
        "def g(x1, y1):\n",
        "    d = np.sqrt((x1 - 0) ** 2 + (y1 - 0) ** 2)\n",
        "    if(d == 0):\n",
        "       return 0\n",
        "    return -128.1 - 37.6 * np.log10(d)\n",
        "\n",
        "def computation_time(D, U, f):\n",
        "    return (D * U) / f\n",
        "\n",
        "def communication_time(B, M, p, N, x, y):\n",
        "    gi = g(x, y)\n",
        "    r = B * np.log2(1 + gi * p / N)\n",
        "    return M / r\n",
        "\n",
        "def computation_energy(D, U, f):\n",
        "    return 10**(-28)*D*U*f**2\n",
        "\n",
        "def communication_energy(tcom, p):\n",
        "    return tcom*p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joXPS06g-weo"
      },
      "outputs": [],
      "source": [
        "def test_model(model, X_test, Y_test):\n",
        "    model.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    loss, acc = model.evaluate(X_test, Y_test, verbose=3, callbacks=[GarbageCollectorCallback()])\n",
        "    return loss, acc\n",
        "\n",
        "def from_FedArtML_to_Flower_format(clients_dict):\n",
        "  list_x_train = []\n",
        "  list_y_train = []\n",
        "  client_names = list(clients_dict.keys())\n",
        "  for client in client_names:\n",
        "    each_client_train=np.array(clients_dict[client],dtype=object)\n",
        "    feat=[]\n",
        "    x_tra=np.array(each_client_train[:, 0])\n",
        "    for row in x_tra:\n",
        "      feat.append(row)\n",
        "    feat=np.array(feat)\n",
        "    y_tra=np.array(each_client_train[:, 1])\n",
        "    list_x_train.append(feat)\n",
        "    list_y_train.append(y_tra)\n",
        "\n",
        "  return list_x_train, list_y_train\n",
        "\n",
        "def get_model():\n",
        "    model = Sequential([\n",
        "        tf.keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='relu', input_shape=(32,32,3), padding='same'), #C1\n",
        "        tf.keras.layers.AveragePooling2D(),\n",
        "        tf.keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='relu', padding='valid'), #C2\n",
        "        tf.keras.layers.AveragePooling2D(),\n",
        "        tf.keras.layers.Dense(120, activation='relu'), \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(84, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def calculate_error_rate(model, test_data, test_label):\n",
        "    predictions = model.predict(test_data, verbose = 3)  # Dự đoán nhãn trên tập kiểm tra\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    error_count = np.sum(predictions != test_label)  # Đếm số lượng mẫu bị phân loại sai\n",
        "    error_rate = error_count / len(test_label)\n",
        "    return error_rate\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train) -> None:\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        er = [calculate_error_rate(self.model, self.x_train, self.y_train)]\n",
        "        for i in range(config[\"epoch\"]):\n",
        "            self.model.compile(optimizer=SGD(learning_rate = config[\"learning_rate\"]), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            self.model.fit(self.x_train, self.y_train, epochs = config['epoch'],verbose=3, batch_size = 64, callbacks=[GarbageCollectorCallback()])\n",
        "            e = calculate_error_rate(self.model, self.x_train, self.y_train)\n",
        "            if e >= er[-1]:\n",
        "                return self.model.get_weights(), len(self.x_train) * (i>0), {\"epoch\" : i}\n",
        "            er.append(e)\n",
        "        return self.model.get_weights(), len(self.x_train) , {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        return loss, len(self.x_test), {\"accuracy\": acc}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhlZEI9f-wep"
      },
      "outputs": [],
      "source": [
        "WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW = \"\"\"\"\"\"\n",
        "\n",
        "class EAMEC(Strategy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        tcom,\n",
        "        tcmp,\n",
        "        alpha,\n",
        "        maxep\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.fraction_fit = fraction_fit\n",
        "        self.fraction_evaluate = fraction_evaluate\n",
        "        self.min_fit_clients = min_fit_clients\n",
        "        self.min_evaluate_clients = min_evaluate_clients\n",
        "        self.min_available_clients = min_available_clients\n",
        "        self.evaluate_fn = evaluate_fn\n",
        "        self.on_fit_config_fn = on_fit_config_fn\n",
        "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
        "        self.accept_failures = accept_failures\n",
        "        self.initial_parameters = initial_parameters\n",
        "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
        "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
        "        self.learning_rate = 0.01\n",
        "        self.decay = 0.995\n",
        "        self.total_time = [tcom[i] + tcmp[i] for i in range(len(tcmp))]\n",
        "        self.training_time = 0\n",
        "        self.round_time = 0\n",
        "        self.energy = 0\n",
        "        self.alpha = alpha\n",
        "        self.max_ep = maxep\n",
        "        self.result = {\"accuracy\": [], \"Completion time\": [0.0], \"energy\": [0.0]}\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        rep = f\"EAMEC\"\n",
        "        return rep\n",
        "\n",
        "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        num_clients = int(num_available_clients * self.fraction_fit)\n",
        "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
        "\n",
        "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
        "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
        "\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        initial_parameters = self.initial_parameters\n",
        "        self.initial_parameters = None\n",
        "        return initial_parameters\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        if self.evaluate_fn is None:\n",
        "            return None\n",
        "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
        "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
        "\n",
        "        loss, metrics = eval_res\n",
        "        self.result[\"accuracy\"].append(metrics[\"accuracy\"])\n",
        "        if server_round == comms_round:\n",
        "            df = pd.DataFrame(self.result)\n",
        "            df.to_csv(f\"result/EA{self.alpha}.csv\", index=False)\n",
        "        return loss, metrics\n",
        "\n",
        "    def configure_fit(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        config = [{\"learning_rate\": self.learning_rate} for _ in range(10)]\n",
        "        sample_size, min_num_clients = self.num_fit_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients, cid = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "        self.round_time = np.max([self.total_time[int(id)] for id in cid])\n",
        "        if server_round % 50 == 0:\n",
        "            for ep in self.max_ep:\n",
        "                ep -= 1\n",
        "                if ep <1:\n",
        "                    ep = 1\n",
        "        epochs = [self.calculate_epoch(id, self.round_time) for id in cid]\n",
        "        for con, ep in zip(config, epochs):\n",
        "            con[\"epoch\"] = min(ep, self.max_ep)\n",
        "        self.result[\"energy\"].append(self.energy+self.result[\"energy\"][-1])\n",
        "        self.energy = 0\n",
        "        fit_ins = [FitIns(parameters, con) for con in config]\n",
        "        return [(client, fit) for client,fit in zip(clients, fit_ins)]\n",
        "\n",
        "    def calculate_epoch(self, client_id, time_threshold):\n",
        "        id = int(client_id)\n",
        "        ep = int(np.ceil((time_threshold - tcom[id]) / (tcmp[id]*2)))\n",
        "        self.energy += ep*ecmp[id]+ecom[id]\n",
        "        return ep\n",
        "\n",
        "    def configure_evaluate(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        if self.fraction_evaluate == 0.0:\n",
        "            return []\n",
        "\n",
        "        config = {}\n",
        "        if self.on_evaluate_config_fn is not None:\n",
        "            config = self.on_evaluate_config_fn(server_round)\n",
        "        evaluate_ins = EvaluateIns(parameters, config)\n",
        "\n",
        "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients,cid = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "        return [(client, evaluate_ins) for client in clients]\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "\n",
        "        weights_results = [\n",
        "                (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "                for _, fit_res in results\n",
        "        ]\n",
        "        aggregated_ndarrays = aggregate(weights_results)\n",
        "        #self.learning_rate *= self.decay ** (np.mean([fit_res.metrics[\"epoch\"] for _, fit_res in results]))\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregated_ndarrays)\n",
        "\n",
        "        metrics_aggregated = {}\n",
        "        self.training_time += self.round_time\n",
        "        self.result[\"Completion time\"].append(self.training_time)\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        loss_aggregated = weighted_loss_avg(\n",
        "            [\n",
        "                (evaluate_res.num_examples, evaluate_res.loss)\n",
        "                for _, evaluate_res in results\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        metrics_aggregated = {}\n",
        "        if self.evaluate_metrics_aggregation_fn:\n",
        "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
        "        return loss_aggregated, metrics_aggregated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDd5C1TH-wes"
      },
      "outputs": [],
      "source": [
        "def evaluate_DNN_CL(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = get_model()\n",
        "    net.set_weights(parameters) # Update model with the latest parameters\n",
        "    loss, accuracy = test_model(net, test_images, test_labels)\n",
        "    return loss, {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9DI6-_Q-weq"
      },
      "outputs": [],
      "source": [
        "class SimpleClientManager(ClientManager):\n",
        "    def __init__(self) -> None:\n",
        "        self.clients: Dict[str, ClientProxy] = {}\n",
        "        self._cv = threading.Condition()\n",
        "        self.seed = 0 # cài đặt seed để fix client tham gia mỗi round\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.clients)\n",
        "\n",
        "    def num_available(self) -> int:\n",
        "        return len(self)\n",
        "\n",
        "    def wait_for(self, num_clients: int, timeout: int = 86400) -> bool:\n",
        "        with self._cv:\n",
        "            return self._cv.wait_for(\n",
        "                lambda: len(self.clients) >= num_clients, timeout=timeout\n",
        "            )\n",
        "\n",
        "    def register(self, client: ClientProxy) -> bool:\n",
        "        if client.cid in self.clients:\n",
        "            return False\n",
        "\n",
        "        self.clients[client.cid] = client\n",
        "        with self._cv:\n",
        "            self._cv.notify_all()\n",
        "\n",
        "        return True\n",
        "\n",
        "    def unregister(self, client: ClientProxy) -> None:\n",
        "        if client.cid in self.clients:\n",
        "            del self.clients[client.cid]\n",
        "\n",
        "            with self._cv:\n",
        "                self._cv.notify_all()\n",
        "\n",
        "    def all(self) -> Dict[str, ClientProxy]:\n",
        "        return self.clients\n",
        "\n",
        "    def sample(\n",
        "        self,\n",
        "        num_clients: int,\n",
        "        min_num_clients: Optional[int] = None,\n",
        "        criterion: Optional[Criterion] = None,\n",
        "    ) -> List[ClientProxy]:\n",
        "    \n",
        "        if min_num_clients is None:\n",
        "            min_num_clients = num_clients\n",
        "        self.wait_for(min_num_clients)\n",
        "        available_cids = list(self.clients)\n",
        "\n",
        "        if num_clients == 1:\n",
        "            sampled_cids = random.sample(available_cids, num_clients)\n",
        "            return [self.clients[cid] for cid in sampled_cids]\n",
        "        \n",
        "        if criterion is not None:\n",
        "            available_cids = [\n",
        "                cid for cid in available_cids if criterion.select(self.clients[cid])\n",
        "            ]\n",
        "        sampled_cids = random.sample(available_cids, num_clients)\n",
        "        return [self.clients[cid] for cid in sampled_cids], sampled_cids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeYIUyLB-wer"
      },
      "outputs": [],
      "source": [
        "colors = [\"#00cfcc\",\"#e6013b\",\"#007f88\",\"#00cccd\",\"#69e0da\",\"darkblue\",\"#FFFFFF\"]\n",
        "local_nodes_glob = 50\n",
        "random_state = 1\n",
        "comms_round =1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBxzssqy-wer"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "train_labels, test_labels = np.concatenate(train_labels), np.concatenate(test_labels)\n",
        "\n",
        "def split_data(alpha):\n",
        "    my_federater = SplitAsFederatedData(random_state = random_state)\n",
        "\n",
        "    clients_glob_dic1, list_ids_sampled_dic1, miss_class_per_node1, distances1 = my_federater.create_clients(image_list = train_images, label_list = train_labels,\n",
        "                                                                num_clients = 50, prefix_cli='client', method = \"dirichlet\", alpha = alpha)\n",
        "    clients_glob1 = clients_glob_dic1['with_class_completion']\n",
        "\n",
        "    list_x_train, list_y_train = from_FedArtML_to_Flower_format(clients_dict=clients_glob1)\n",
        "    return list_x_train, list_y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Counter\n",
        "def calculate_entropy(y_train):\n",
        "      counts = Counter(y_train)\n",
        "      entropy = 0.0\n",
        "      counts = list(counts.values())\n",
        "      counts = [0 if value is None else value for value in counts]\n",
        "      for value in counts:\n",
        "          entropy += -value/sum(counts) * math.log(value/sum(counts), 10) if value != 0 else 0\n",
        "      return entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygjddEdr-wes"
      },
      "outputs": [],
      "source": [
        "model = get_model()\n",
        "\n",
        "for i in range(1, 10):\n",
        "    alpha = i*10\n",
        "    list_x_train, list_y_train = split_data(i)  \n",
        "    tcmp = [computation_time(len(list_x_train[i])*3, U[i], f[i]) for i in range(50)]\n",
        "    tcom = [communication_time(B[i], M, p[i], N, x[i], y[i]) for i in range(50)]\n",
        "    ecmp = [computation_energy(len(list_x_train[i])*3, U[i], f[i]) for i in range(50)]\n",
        "    ecom = [communication_energy(tcom[i], p[i]) for i in range(50)]\n",
        "\n",
        "    entropies = [calculate_entropy(np.array(list_y_train[int(cid)],dtype=int)) for cid in range(len(list_y_train))]\n",
        "\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        x_train_cid = np.array(list_x_train[int(cid)],dtype=float)\n",
        "        y_train_cid = np.array(list_y_train[int(cid)],dtype=int)\n",
        "        return FlowerClient(model, x_train_cid, y_train_cid)\n",
        "\n",
        "    strategy=EAMEC(\n",
        "            fraction_fit=0.2,\n",
        "            fraction_evaluate=0,\n",
        "            min_fit_clients=10,\n",
        "            min_available_clients = 50,\n",
        "            evaluate_fn=evaluate_DNN_CL,\n",
        "            tcom = tcom,\n",
        "            tcmp = tcmp,\n",
        "            alpha = alpha,\n",
        "            maxep= [3 if x >= 0.9 else 2 for x in range(50)]\n",
        "    )\n",
        "\n",
        "    clientmanager = SimpleClientManager()\n",
        "\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=local_nodes_glob,\n",
        "        config=fl.server.ServerConfig(num_rounds=comms_round),\n",
        "        strategy=strategy,\n",
        "        client_manager = clientmanager,\n",
        "        client_resources = {'num_cpus': 1, 'num_gpus': 0},\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYxZs8Rv-wet"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
